{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from xrkit.base import CONFIG\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv(Path(CONFIG.data.raw.path, \"Data_Entry_2017.csv\"), nrows=1000)\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_counts = info[\"Finding Labels\"].value_counts()[:15]\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax1.bar(np.arange(len(label_counts)) + 0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts)) + 0.5)\n",
    "_ = ax1.set_xticklabels(label_counts.index, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv(Path(CONFIG.data.raw.path, \"BBox_List_2017.csv\"))\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = info[\"Image Index\"]\n",
    "top_left_y = info[\"Finding Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, top_left_y, test_size=0.2, stratify=top_left_y, random_state=34\n",
    ")\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = info.sample(frac=0.15, random_state=34)\n",
    "test[\"Finding Label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = info[info[\"Image Index\"].isin(X_test.tolist())]\n",
    "# test['Finding Label'].value_counts(normalize=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = info[info[\"Image Index\"].isin(X_train.tolist())]\n",
    "train[\"Finding Label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "\n",
    "IMAGE_SIZE = CONFIG.base.image_size\n",
    "\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, data_subset: str):\n",
    "        self.data_subset = data_subset\n",
    "\n",
    "        self.transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.set_info = self.split_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.set_info)\n",
    "\n",
    "    def __getitem__(self, index, transform=True):\n",
    "        image_path = train.iloc[index][\"Image Index\"]\n",
    "        top_left_x, top_left_y, width, height = (\n",
    "            train.iloc[index][[\"Bbox [x\", \"y\", \"w\", \"h]\"]].astype(int).values\n",
    "        )\n",
    "        image = Image.open(next(Path(CONFIG.data.raw.path).rglob(image_path)).as_posix())\n",
    "\n",
    "        image_shape = image.size[::-1]\n",
    "        mask = np.zeros(image_shape, dtype=np.uint8)\n",
    "        mask[top_left_y : top_left_y + height, top_left_x : top_left_x + width] = 255.0\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        if transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def split_data(self):\n",
    "        self.info = pd.read_csv(Path(CONFIG.data.raw.path, \"BBox_List_2017.csv\"))\n",
    "\n",
    "        X = info[\"Image Index\"]\n",
    "        y = info[\"Finding Label\"]\n",
    "\n",
    "        X_train, X_test, _, _ = train_test_split(X, y, test_size=0.2, stratify=y, random_state=34)\n",
    "        train_subset = info[info[\"Image Index\"].isin(X_train.tolist())]\n",
    "        test_subset = info[info[\"Image Index\"].isin(X_test.tolist())]\n",
    "\n",
    "        data_mapping = {\"train\": train_subset, \"test\": test_subset}\n",
    "\n",
    "        if self.data_subset in data_mapping:\n",
    "            return data_mapping[self.data_subset]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid data type. Choose from 'train' or 'test'.\")\n",
    "\n",
    "\n",
    "image, mask = SegmentationDataset(data_subset=\"train\").__getitem__(2, transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_image = image.numpy()[0] * 255\n",
    "adj = Image.fromarray(adjusted_image)\n",
    "\n",
    "adjusted_image = mask.numpy()[0] * 255\n",
    "adj2 = Image.fromarray(adjusted_image)\n",
    "\n",
    "display([adj.show(), adj2.show()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = SegmentationDataset(data_subset=\"train\").__getitem__(2)\n",
    "# image_shape = (512, 512)  # Example image shape\n",
    "# x, y, w, h = 10, 20, 30, 40\n",
    "# mask = np.zeros(image_shape, dtype=np.uint8)\n",
    "# mask[y: y+h, x: x+w] = 255\n",
    "# Image.fromarray(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path, top_left_x, top_left_y, width, height = (\n",
    "    train.reset_index(drop=True).iloc[0][[\"Image Index\", \"Bbox [x\", \"y\", \"w\", \"h]\"]].values\n",
    ")\n",
    "image_path, top_left_x, top_left_y, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(CONFIG.data.raw.path, \"test_list.txt\"), \"r\") as file:\n",
    "    test_list = [line.strip() for line in file.readlines()]\n",
    "\n",
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(CONFIG.data.raw.path, \"train_val_list.txt\"), \"r\") as file:\n",
    "    train_val_list = [line.strip() for line in file.readlines()]\n",
    "\n",
    "train_val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 512\n",
    "BATCH_SIZE = 16\n",
    "NUMBER = 100\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class LowLightDataset(Dataset):\n",
    "    def __init__(self, image_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Lambda(lambda x: x / 255.0),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "def data_generator(low_light_images):\n",
    "    dataset = LowLightDataset(low_light_images)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True, drop_last=False\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "images = [image.as_posix() for image in Path(BASE_PATH, CONFIG.data.raw.path).rglob(\"*.png\")]\n",
    "\n",
    "low_light_images = images[:100]\n",
    "dataloader = data_generator(low_light_images)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [image.as_posix() for image in Path(BASE_PATH, CONFIG.data.raw.path).rglob(\"*.png\")]\n",
    "\n",
    "train_low_light_images = images[: 1 * NUMBER]\n",
    "val_low_light_images = images[1 * NUMBER : 2 * NUMBER]\n",
    "test_low_light_images = images[2 * NUMBER : 3 * NUMBER]\n",
    "\n",
    "\n",
    "train_loader = data_generator(train_low_light_images)\n",
    "validation_loader = data_generator(val_low_light_images)\n",
    "\n",
    "print(\"Train Dataset:\", train_loader)\n",
    "print(\"Validation Dataset:\", validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = next(iter(train_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nih",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
