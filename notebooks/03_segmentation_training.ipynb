{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imont\\anaconda3\\envs\\nih\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"imonteiroyh/NIH-ChestXRay\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"imonteiroyh/NIH-ChestXRay\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository imonteiroyh/NIH-ChestXRay initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository imonteiroyh/NIH-ChestXRay initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "from xrkit.base import CONFIG\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from xrkit.data import SegmentationDataset\n",
    "from xrkit.models import *\n",
    "\n",
    "os.chdir(\"..\")\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "dagshub.init(CONFIG.dagshub.repository_name, CONFIG.dagshub.repository_owner, mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SegmentationDataset(\"train\")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.base.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG.base.n_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "validation_dataset = SegmentationDataset(\"validation\")\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=CONFIG.base.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG.base.n_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = SegmentationDataset(\"test\")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG.base.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG.base.n_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "inputs, targets = next(iter(train_loader))\n",
    "outputs = DenseNet201UNetModel(n_epochs=1).network(inputs)\n",
    "\n",
    "tensor_normalized = (outputs[0] - outputs[0].min()) / (outputs[0].max() - outputs[0].min())\n",
    "tensor_image = tensor_normalized * 255\n",
    "\n",
    "image_stack = []\n",
    "\n",
    "for batch in range(tensor_image.shape[0]):\n",
    "    pil_image = Image.fromarray(tensor_image[batch].detach().numpy())\n",
    "\n",
    "    image_stack.append(pil_image)\n",
    "\n",
    "for batch, img in enumerate(image_stack):\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "models.densenet201()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# model = DenseNet201UNetModel(n_epochs=epochs)\n",
    "# model = NASNetLargeUNetModel(n_epochs=epochs)\n",
    "# model = ResNet152V2UNetModel(n_epochs=epochs)\n",
    "model = VGG19UNetModel(n_epochs=epochs)\n",
    "\n",
    "experiment_name = model.__class__.__name__.lower()[:-5]\n",
    "metric, mode = \"validation_loss\", \"min\"\n",
    "\n",
    "logger = MLFlowLogger(experiment_name=experiment_name, tracking_uri=CONFIG.dagshub.tracking_uri)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=metric,\n",
    "    dirpath=f\"models/{experiment_name}\",\n",
    "    filename=\"model-{epoch:03d}-{validation_loss:.2f}\",\n",
    "    save_top_k=1,\n",
    "    mode=mode,\n",
    "    enable_version_counter=False,\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=metric, min_delta=0.00, patience=10, mode=mode)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=epochs, logger=logger, callbacks=[checkpoint_callback, early_stop_callback])\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 1\n",
    "input = torch.randn((4, n_channels, 128, 128))\n",
    "model = InceptionV3(task=\"segmentation\", n_inputs=n_channels)\n",
    "print(model(input).shape)\n",
    "\n",
    "from torchview import draw_graph\n",
    "import graphviz\n",
    "\n",
    "# graphviz.set_jupyter_format(\"png\")\n",
    "\n",
    "# draw_graph(model, input_size=input.shape, expand_nested=True, depth=3).visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "model = timm.create_model(\"resnet152d\", pretrained=True, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "from xrkit.base import CONFIG\n",
    "\n",
    "\n",
    "batch_size = CONFIG.base.batch_size\n",
    "model\n",
    "summary(nn.Sequential(*list(model.children()))[:-2], input_size=(batch_size, 3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchview import draw_graph\n",
    "import graphviz\n",
    "\n",
    "graphviz.set_jupyter_format(\"png\")\n",
    "\n",
    "draw_graph(models.inception_v3(), input_size=input.shape, expand_nested=True, depth=3).visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn((4, 3, 256, 256))\n",
    "models.inception_v3()(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "input = torch.randn((4, 3, 128, 128))\n",
    "model = timm.create_model(\"legacy_xception\", pretrained=True, num_classes=10000)\n",
    "model = nn.Sequential(*list(model.children()))[-2:]\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.vgg19()\n",
    "network.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchview import draw_graph\n",
    "import graphviz\n",
    "\n",
    "graphviz.set_jupyter_format(\"png\")\n",
    "\n",
    "draw_graph(model.network, input_size=(4, 1, 256, 256), expand_nested=True, depth=2).visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Resume Training\n",
    "# trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=validation_loader, ckpt_path='models/unet/model-epoch=000-validation_fbeta_score=0.63.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNetModel.load_from_checkpoint(\"models/unet/model-epoch=000-validation_fbeta_score=0.00.ckpt\")\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(\"models/unet/model-epoch=000-validation_fbeta_score=0.00.ckpt\")\n",
    "\n",
    "# # Extraindo o estado do dicionário\n",
    "# state_dict = checkpoint[\"state_dict\"]\n",
    "\n",
    "# # Carregando a estrutura do modelo\n",
    "# k = UNetModel(n_epochs=epochs)\n",
    "\n",
    "# # Carregando o estado do dicionário no modelo\n",
    "# k.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer2 = L.Trainer(logger=logger)\n",
    "# trainer2.test(model=model, dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
